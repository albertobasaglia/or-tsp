\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{import}
\usepackage{subcaption}

\graphicspath{./assets/}

\title{Performance Analysis of TSP Solving Algorithms}
\author{Basaglia Alberto, Stocco Andrea}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
	The Traveling Salesman Problem (TSP) is one of the most intensively studied problems in optimization.
	It asks the following question:\\\\
	\textit{Given a list of cities and the distances between each pair of cities, what is the shortest possible route
	that visits each city exactly once and returns to the origin city?}\\\\
	TSP is computationally difficult (NP-Hard), but there exist many \textit{heuristics} and \textit{exact algorithms} to solve it.
	In this thesis we are going to show and compare the performances of these algorithms.
\end{abstract}

\section{Introduction}
In this study we focus on evaluating the performance of two heuristic algorithms: the \textit{Greedy} algorithm with \textit{2-opt}
optimization and the \textit{Tabu Search} algorithm.
The Greedy algorithm, starting from every possible node of the instance, tries to find the optimal solution always updating the path
with the closest node. To improve the performance of this algorithm, after that, we apply also the 2-opt algorithm, to remove
the intersection between the edges of the path.
On the other hand, the Tabu Search algorithm, starting from a random node, tries to `move`... TODO

\section{Heuristics}
Heuristics are algorithms to determine a near-optimal solution to an optimization problem. In certain scenarios, 
exact methods aren't able to provide the optimal solution in a reasonable amount of time or they can't find it
at all. In contrast, a heuristic is generally capable of offering a solution that is more or less close to
the optimal one.
While there is no assurance regarding the optimality of the provided solution, it may still be considered
acceptable in some instances.

\subsection{Greedy}
A greedy algorithm is a heuristic that attempts to find an optimal solution by selecting the best possible choice at each iteration.
For instance, in our case, when determining the next node to visit, the greedy algorithm will always choose
the nearest unvisited one. Algorithm \ref{alg:greedy} shows the pseudocode of this procedure

\begin{algorithm}[h]
\caption{Greedy}
\label{alg:greedy}
\hspace*{0.5em} \textbf{Output}: $solution$
\begin{algorithmic}
  \Procedure{greedy}{$startingnode, nnodes$}

	\State $solution \gets {0, 1, \dots, nnodes - 1}$
	\State $solution \gets \Call{swap}{solution, 0, startingnode}$
    \For{$i \gets 0$ to $nnodes - 1$}
		\State $mindist \gets \infty$
		\State $minindex \gets -1$
		\For{$j \gets i + 1$ to $nnodes$}
			\If{$dist(i, j) < mindist$}
				\State $mindist \gets dist(i, j)$
				\State $minindex \gets j$
			\EndIf
		\EndFor
		\State $solution \gets \Call{swap}{solution, i + 1, minindex}$
    \EndFor

  \EndProcedure

\end{algorithmic}
\end{algorithm}
Repeating this procedure for every possible starting node, we'll be able to find the best
achievable solution.
However, the solution found by this algorithm could have a lot of `intersections`
(TODO explain what intersections are maybe with a figure)

\subsection{2-opt}
The 2-opt algorithm is an optimization technique that can be used to improve a sub-optimal solution.
It evaluates the possibility of removing two edges in the tour and reconnecting the now disconnected nodes in the other way.
This process aims to improve the cost of the tour by eliminating inefficient segments while preserving the overall tour structure. By
iteratively exploring these adjustments and accepting them if they result in a shorter tour cost, the algorithm gradually refines
the solution. This iterative refinement continues until no further improvements can be made, resulting in a more
solution closer to the optimal one for the given problem instance.
Although it is not the only possible situation where a 2-opt move could be
beneficial, figure~\ref{fig:2optmove} illustrates an example of such a move.

\begin{figure}[H]
        \caption{Example of a 2-opt move}
        \label{fig:2optmove}
        \centering
        \begin{subfigure}{.5\textwidth}
                \centering
                \def\svgwidth{.7\linewidth}
                \import{assets}{2opt-pre.pdf_tex}
                \caption{Before the move}
        \end{subfigure}%
        \begin{subfigure}{.5\textwidth}
                \centering
                \def\svgwidth{.7\linewidth}
                \import{assets}{2opt-post.pdf_tex}
                \caption{After the move}
        \end{subfigure}
\end{figure}

It's easy to see that the removal of the crossing edges is beneficial to the
cost of the solution.

Algorithm \ref{alg:greedy_2opt} shows a possible implementation of this procedure to improve
the solution found by greedy.

\begin{algorithm}[h]
\caption{Best 2-opt Swap}
\label{alg:best2optswap}
\hspace*{0.5em} \textbf{Output}: $bestsolution$
\begin{algorithmic}
	\Procedure{best2optswap}{$solution, nnodes$}
	    \State $bestsolution \gets solution$
	    \For{$i \gets 0$ to $nnodes - 2$}
	        \For{$j \gets i + 2$ to $nnodes$}
	            \State $newsolution \gets \Call{reversesubsequence}{solution, i + 1, j}$
	            \If{$\Call{cost}{newsolution} < \Call{cost}{bestsolution}$}
	                \State $bestsolution \gets newsolution$
	            \EndIf
	        \EndFor
	    \EndFor
	\EndProcedure
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
\caption{Greedy + 2-opt}
\label{alg:greedy_2opt}
\hspace*{0.5em} \textbf{Output}: $solution$
\begin{algorithmic}
  \Procedure{greedy2opt}{$nnodes$}
	\State $solution \gets \emptyset$
	\State $solutioncost \gets \infty$
	\ForAll{$node \in tsp$}
		\State $currentsolution \gets \Call{greedy}{node, nnodes}$
		\While{$true$}
			\State $2optsolution \gets \Call{best2optswap}{currentsolution, nnodes}$
			\If{$\Call{cost}{2optsolution} < \Call{cost}{currentsolution}$}
				\State $currentsolution \gets 2optsolution$
			\Else
				\State $break$
			\EndIf
		\EndWhile
		\If{$\Call{cost}{currentsolution} < solutioncost$}
			\State $solution \gets currentsolution$
			\State $solutioncost \gets \Call{cost}{currentsolution}$
		\EndIf
	\EndFor
  \EndProcedure

\end{algorithmic}
\end{algorithm}

\section{Metaheuristics}
A metaheuristic is a versatile problem-solving approach characterized by its iterative nature and adaptability across various optimization problems. Unlike specific algorithms tailored to particular problems, metaheuristics serve as overarching strategies that guide subordinate heuristics to efficiently explore and exploit solution spaces. They intelligently combine different concepts to navigate through search spaces, aiming to find near-optimal solutions effectively.
In our experiments, we will adopt metaheuristic using \textit{2-opt} as the underlying
heuristic. We will prove that simple but very clever ideas (like Tabu Search and VNS) combined with the previously seen heuristics allow us to get solutions very close to the optimal ones.

\subsection{Tabu Search}
Tabu Search is a metaheuristic algorithm that efficiently explores the solution space by intelligently navigating through a neighborhood of solutions while maintaining a short-term memory to avoid revisiting previously visited or less promising solutions. The algorithm is particularly effective for combinatorial optimization problems like the Traveling Salesman Problem (TSP).

By design, this procedure will initially head directly towards a local minimum, thanks to the underlying heuristic. The only purpose of this metaheuristic is then to escape it and, hopefully, converge to a better minimum.

The search procedure will be alternating between 2 different behaviors by its nature. First of all
we will identify a phase where the method, starting from a ``bad'' solution, uses the underlying
heuristic to improve its cost. We will call this ``intensification phase''. Once a local minimum is reached, we will apply some bad moves to escape from this solution. We name this the ``diversification phase''. We hope that the alternation between improving the solution and moving
away from it allows us to explore different local minimum, allowing us to get an overall better
solution.

Algorithm~\ref{alg:tabu} shows a very abstract description of the procedure we use in practice. The first solution is found using a greedy method (the closest neighbor apporach) and then \textit{2-opt} is used for the intensification phase. It is important to notice that $delta$ is
how much the solution cost would improve (decrease by).

\begin{algorithm}[h]
\caption{Tabu Search}
\label{alg:tabu}
\begin{algorithmic}
  \Procedure{tabusearch}{$solution$}
    \State\Call{greedy}{solution}
    \State $tabulist \gets \emptyset$

    \While{$!stop$}
        \State $move \gets \Call{findbestswapnotabu}{solution, tabulist}$
        \State $delta \gets \Call{delta}{move}$
        \State $solution \gets \Call{apply}{solution, move}$
        \If{$delta \leq 0$}
          \State $tabulist \gets tabulist \cup \{move\}$
        \EndIf
        \State $\Call{removeold}{tabulist}$
    \EndWhile

  \EndProcedure

\end{algorithmic}
\end{algorithm}

The procedure begins by solving the problem with a greedy approach and the tabu list
is empty. All the procedure is executed in a while loop with a generic condition. We could
decide to exit the loop in a large variety of ways. In our experiments we leave the loop
after a predefined time-limit. Other possibilities can involve a maximum number of iterations, a lack of any improvement in the last iterations or any other kind of stopping criteria.

At every iteration of the loop, we find the best move that is not in the tabu list. If this move has a positive delta (meaning that its application would lead to an
improvement in the solution) we apply it and jump to the next iteration. If the best
move has a negative delta we apply it anyway, adding it to the list of the tabu moves.

It is then important to define a way to remove moves from the list. In the pseudo-code we define it with a generic ``removeold'' function, in practice there are many ways the remove tabu entries.

We define ``tenure'' of the tabu method the window of iteration in which tabu moves are considered. For example a tenure of $100$ iterations would mean that we remove
from the tabu list all moves that weren't added in the last $100$ iterations.

This \textit{hyperparameter} is crucial for the effectiveness of the method. In our implementation we experimented with a fixed tenure (dependent on the number of
nodes of the instance) and with some functions of the number of the current iteration. Some good results were obtained with a sinusoidal function.

This approach using variable values for the tenure can be quite effective compared to a fixed one as we will se in the chapted dedicated to experimental results.
An intuition behind this can be given by the fact that varying the tenure can be beneficial to the search of a new minimum because it tries to solve both the problems of having a tenure that is too big and one that is too small.
A small tenure can be problematic because we cannot escape the local minimum far enough. A big tenure has the disadvantage that we might find ourselves in a situation where the move needed to reach a new local minimum is blocked by the
tabu list. Having a variable tenure can sometimes, on the long run, avoid the drawbacks of a fixed approach.

\subsection{VNS (Variable Neighborhood Search)}
In \textit{Tabu Search} we have seen two different phases: 
\begin{itemize}
	\item the \textit{Intensification Phase} to move towards a better solution
	\item the \textit{Diversification Phase} in which we try to `escape` from a local minimum using only
	non-tabu moves
\end{itemize}
With this approach, we may spend a considerable amount of time without achieving any improvement in 
solution quality (Diversification Phase). One potential solution could involve restarting from a random 
point each time we encounter a local minimum (Multistart). However, this approach would significantly 
prolong the Intensification Phase. Moreover, when encountering a local minimum, it is probable 
that the solution obtained is not entirely incorrect but requires adjustment in some aspect.
VNS is a metaheuristic that employs minimal permutations of the solution to evade local minima, as 
opposed to restarting from a completely different starting point.
With this approach, we transition from one solution to a better one using the 2-opt method until reaching 
a local minimum. Subsequently, we perform a random number of permutations involving three nodes (3-opt)
to navigate away from the minimum. This approach also ensures that we never revert to a previously visited
solution in the last 2-opt application, as it cannot be achieved through a sequence of permutations of
three nodes.
This is a simplified version of the algorithm; state-of-the-art techniques also allow for larger permutations
of nodes (e.g., 4-opt, 5-opt, etc.) instead of multiple 3-opt operations.
Algorithm~\ref{alg:vns} shows a very abstract description of the procedure

\begin{algorithm}[h]
\caption{VNS}
\label{alg:vns}
\begin{algorithmic}
  \Procedure{vns}{$solution$}
    \State\Call{greedy}{solution}

    \While{$!stop$}
        \State $move \gets \Call{findbest2optswap}{solution}$
        \State $delta \gets \Call{delta}{move}$
        \If{$delta \leq 0$}
			\For{$\Call{random}{range}$}
				\State $move \gets \Call{find3optswap}{solution}$
		        \State $solution \gets \Call{apply}{solution, move}$
			\EndFor
		\Else
			\State $solution \gets \Call{apply}{solution, move}$
		\EndIf
    \EndWhile

  \EndProcedure

\end{algorithmic}
\end{algorithm}

\clearpage

\section{Exact Methods}
Although, as we will see, a good heuristic can achieve very good results, it is also
important to consider approaches that lead to an optimal solution of the
TSP problem.

All of the techniques that we will cover are based on integer linear programming. It is
hence useful to provide an integer linear formulation for the problem.
Many formulations exist, but the one we will focus on is the one proposed by
Dantzig, Fulkerson and Johnson. % TODO cite https://pubsonline.informs.org/doi/10.1287/opre.2.4.393

Initally we define an undirected complete graph $G=(V, E)$.
We will the use $c_e : E \rightarrow \mathbb{R}^+$ to indicate the cost of
an edge.
One of the ways to compute this cost function is to place all the points
on a 2d surface and compute their eucledian distance.

The variables of this model are
\begin{equation*}
        x_e =
        \left\{
                \begin{array}{l}
                1 \text{ the path uses edge $e$}\\
                0 \text{ otherwise }
        \end{array}
        \right.
\end{equation*}

The model, that makes use of the subtour elimination constraints, is the
following
\begin{equation}
  \begin{aligned}
\min & \sum_{e \in E} c_e x_e \\
\text{s.t.}
& \sum_{e \in \delta(h)} x_{e} = 2 \quad \forall h \in V \\
& \sum_{e \in E(S)} x_{e} \leq |S| - 1 \quad \forall S \subset V : |S| \geq 3 \\
& x_{e} \in \{0, 1\} \quad \forall e \in E.
\end{aligned}
\end{equation}
$\delta(h)$, where $h$ is a node, is defined as the set of edges that are
incident to $h$. $E(S)$, where $S$ is a set of nodes, is the est of all the
the edges with both extremities in $S$.

It is important to know that the number of SECs is exponential in the number of
the nodes. Hence, it is infeasible to generate all of them from the beginning
with the size of the instances we are interested in. We will show more than
one way to add them dynamically.

\subsection{Benders' loops}
The first technique we will explore is the so called ``Benders' loops'' technique.
The basic idea behind this approach is the iterated use of a MIP solver (like CPLEX)
as a black-box. More precisely, we will start by providing the solver with
a model lacking all the separation constraints. The solution of this model,
with all probability, is going to contain more than one loop. We will then
generate some constraints "cutting" the solution we have found.
The model, updated with the new constraints, is then passed to the solver
and solved again. This loop will be repeated until a solution composed by
only one component is found.
The process is described in Figure~\ref{fig:benders}.

\begin{figure}[h]
        \caption{Solving using Benders' loops}
        \label{fig:benders}
        \centering
        \includegraphics[width=340pt]{assets/bendersloops.drawio.pdf}
\end{figure}

\section{Results}

\end{document}
